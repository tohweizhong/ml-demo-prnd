{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db7b70fe66ffbab974b8ef6cab59a2bd3c717330"
   },
   "source": [
    "## K-Means Clustering and PCA of Human Activity Recognition\n",
    "\n",
    "***Ruslan Klymentiev***\n",
    "\n",
    "**Date created: **July 21st, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5fccfee7b9af1771dd838e1c7ee7a726be3f1acc"
   },
   "source": [
    "### Intro\n",
    "\n",
    "Clustering was always a subject I tried to avoid (for no reason). In this project I will finally use my knowledge of clustering and PCA algorithms to explore the Human Activity Recognition dataset. \n",
    "\n",
    "I would love to point on resourses I have learned from:\n",
    "\n",
    "1. DataCamp Tutorial: [Python Machine Learning: Scikit-Learn Tutorial](https://www.datacamp.com/community/tutorials/machine-learning-python);\n",
    "\n",
    "2. DataCamp course: [Unsupervised Learning in Python](https://www.datacamp.com/courses/unsupervised-learning-in-python/);\n",
    "\n",
    "3. Cognitive Class course: [Machine Learning with Python](https://courses.cognitiveclass.ai/courses/course-v1:CognitiveClass+ML0101ENv3+2018/info);\n",
    "\n",
    "4. And of course [Prof. Google](http://google.com)!\n",
    "\n",
    "### Dataset info\n",
    "\n",
    "Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (*WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING*) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, \\\n",
    "v_measure_score, adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv('../data/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0d75d9a39ca8762b4094ba03884aa4891a53bfb6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rn</th>\n",
       "      <th>activity</th>\n",
       "      <th>tBodyAcc.mean.X</th>\n",
       "      <th>tBodyAcc.mean.Y</th>\n",
       "      <th>tBodyAcc.mean.Z</th>\n",
       "      <th>tBodyAcc.std.X</th>\n",
       "      <th>tBodyAcc.std.Y</th>\n",
       "      <th>tBodyAcc.std.Z</th>\n",
       "      <th>tBodyAcc.mad.X</th>\n",
       "      <th>tBodyAcc.mad.Y</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag.meanFreq</th>\n",
       "      <th>fBodyBodyGyroJerkMag.skewness</th>\n",
       "      <th>fBodyBodyGyroJerkMag.kurtosis</th>\n",
       "      <th>angle.tBodyAccMean.gravity</th>\n",
       "      <th>angle.tBodyAccJerkMean.gravityMean</th>\n",
       "      <th>angle.tBodyGyroMean.gravityMean</th>\n",
       "      <th>angle.tBodyGyroJerkMean.gravityMean</th>\n",
       "      <th>angle.X.gravityMean</th>\n",
       "      <th>angle.Y.gravityMean</th>\n",
       "      <th>angle.Z.gravityMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1739</td>\n",
       "      <td>WALKING_UPSTAIRS</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.00873</td>\n",
       "      <td>-0.1060</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>-0.0801</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>0.315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358</td>\n",
       "      <td>-0.726</td>\n",
       "      <td>-0.9410</td>\n",
       "      <td>0.86900</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.916</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>6598</td>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.03990</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>-0.1330</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.5850</td>\n",
       "      <td>0.09500</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>0.937</td>\n",
       "      <td>-0.6360</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>2291</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.02310</td>\n",
       "      <td>-0.0998</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.9650</td>\n",
       "      <td>-0.9690</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-0.9560</td>\n",
       "      <td>-0.12800</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.420</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>-0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>4615</td>\n",
       "      <td>LAYING</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.03790</td>\n",
       "      <td>-0.1530</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>-0.5340</td>\n",
       "      <td>-0.7920</td>\n",
       "      <td>-0.647</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>-0.7290</td>\n",
       "      <td>0.00812</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>4111</td>\n",
       "      <td>WALKING</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.04250</td>\n",
       "      <td>-0.0977</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>-0.0342</td>\n",
       "      <td>-0.2350</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.30500</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-0.4360</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rn            activity  tBodyAcc.mean.X  tBodyAcc.mean.Y  \\\n",
       "613   1739    WALKING_UPSTAIRS            0.241         -0.00873   \n",
       "2306  6598  WALKING_DOWNSTAIRS            0.238         -0.03990   \n",
       "800   2291              LAYING            0.280         -0.02310   \n",
       "1621  4615              LAYING            0.320          0.03790   \n",
       "1436  4111             WALKING            0.211         -0.04250   \n",
       "\n",
       "      tBodyAcc.mean.Z  tBodyAcc.std.X  tBodyAcc.std.Y  tBodyAcc.std.Z  \\\n",
       "613           -0.1060          -0.216          0.3220         -0.0801   \n",
       "2306          -0.1580           0.284          0.2270         -0.1330   \n",
       "800           -0.0998          -0.978         -0.9650         -0.9690   \n",
       "1621          -0.1530          -0.642         -0.5340         -0.7920   \n",
       "1436          -0.0977          -0.324         -0.0342         -0.2350   \n",
       "\n",
       "      tBodyAcc.mad.X  tBodyAcc.mad.Y         ...           \\\n",
       "613           -0.267           0.315         ...            \n",
       "2306           0.245           0.214         ...            \n",
       "800           -0.980          -0.964         ...            \n",
       "1621          -0.647          -0.615         ...            \n",
       "1436          -0.362          -0.031         ...            \n",
       "\n",
       "      fBodyBodyGyroJerkMag.meanFreq  fBodyBodyGyroJerkMag.skewness  \\\n",
       "613                           0.358                         -0.726   \n",
       "2306                          0.302                         -0.190   \n",
       "800                           0.494                         -0.863   \n",
       "1621                          0.309                         -0.388   \n",
       "1436                          0.241                          0.320   \n",
       "\n",
       "      fBodyBodyGyroJerkMag.kurtosis  angle.tBodyAccMean.gravity  \\\n",
       "613                         -0.9410                     0.86900   \n",
       "2306                        -0.5850                     0.09500   \n",
       "800                         -0.9560                    -0.12800   \n",
       "1621                        -0.7290                     0.00812   \n",
       "1436                         0.0199                     0.30500   \n",
       "\n",
       "      angle.tBodyAccJerkMean.gravityMean  angle.tBodyGyroMean.gravityMean  \\\n",
       "613                                0.337                           -0.916   \n",
       "2306                              -0.684                            0.937   \n",
       "800                                0.262                           -0.098   \n",
       "1621                              -0.139                            0.170   \n",
       "1436                              -0.493                            0.727   \n",
       "\n",
       "      angle.tBodyGyroJerkMean.gravityMean  angle.X.gravityMean  \\\n",
       "613                                0.7750               -0.686   \n",
       "2306                              -0.6360               -0.749   \n",
       "800                                0.0558                0.420   \n",
       "1621                               0.5200                0.685   \n",
       "1436                              -0.4360               -0.572   \n",
       "\n",
       "      angle.Y.gravityMean  angle.Z.gravityMean  \n",
       "613                 0.314                0.034  \n",
       "2306                0.235                0.127  \n",
       "800                -0.278               -0.714  \n",
       "1621               -0.250               -0.760  \n",
       "1436                0.344                0.182  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c778c9d35c5a36800c8fe54b8584febf066d52cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set: (3609, 563)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the data set: ' + str(Data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0ce7fbd3acc1b4a8126030208c93cbb28c8f7dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity labels: ['STANDING', 'SITTING', 'LAYING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS']\n"
     ]
    }
   ],
   "source": [
    "#save labels as string\n",
    "Labels = Data['activity']\n",
    "Data = Data.drop(['rn', 'activity'], axis = 1)\n",
    "Labels_keys = Labels.unique().tolist()\n",
    "Labels = np.array(Labels)\n",
    "print('Activity labels: ' + str(Labels_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2c37995ce0245b2daf2f4172a889dd24cbe3aa8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of rows with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "Temp = pd.DataFrame(Data.isnull().sum())\n",
    "Temp.columns = ['Sum']\n",
    "print('Amount of rows with missing values: ' + str(len(Temp.index[Temp['Sum'] > 0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2fbedddd526219ed7c20866c1908910c2eec9173",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "Data = scaler.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fdbd26ac5a9a1010601f69bfc9016a18a7754f33",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check the optimal k value\n",
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(Data)\n",
    "    inertias.append(model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.style.use('bmh')\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('Number of clusters, k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91cfe23cbfe44daebbd2f92523f511b90c6cb69e"
   },
   "source": [
    "**Looks like the best value (\"elbow\" of the line) for k is 2 (two clusters).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7188fdd938b8ac2d13a27532549fd39891a4fcfc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_means(n_clust, data_frame, true_labels):\n",
    "    \"\"\"\n",
    "    Function k_means applies k-means clustering alrorithm on dataset and prints the crosstab of cluster and actual labels \n",
    "    and clustering performance parameters.\n",
    "    \n",
    "    Input:\n",
    "    n_clust - number of clusters (k value)\n",
    "    data_frame - dataset we want to cluster\n",
    "    true_labels - original labels\n",
    "    \n",
    "    Output:\n",
    "    1 - crosstab of cluster and actual labels\n",
    "    2 - performance table\n",
    "    \"\"\"\n",
    "    k_means = KMeans(n_clusters = n_clust, random_state=123, n_init=30)\n",
    "    k_means.fit(data_frame)\n",
    "    c_labels = k_means.labels_\n",
    "    df = pd.DataFrame({'clust_label': c_labels, 'orig_label': true_labels.tolist()})\n",
    "    ct = pd.crosstab(df['clust_label'], df['orig_label'])\n",
    "    y_clust = k_means.predict(data_frame)\n",
    "    display(ct)\n",
    "    print('% 9s' % 'inertia  homo    compl   v-meas   ARI     AMI     silhouette')\n",
    "    print('%i   %.3f   %.3f   %.3f   %.3f   %.3f    %.3f'\n",
    "      %(k_means.inertia_,\n",
    "      homogeneity_score(true_labels, y_clust),\n",
    "      completeness_score(true_labels, y_clust),\n",
    "      v_measure_score(true_labels, y_clust),\n",
    "      adjusted_rand_score(true_labels, y_clust),\n",
    "      adjusted_mutual_info_score(true_labels, y_clust),\n",
    "      silhouette_score(data_frame, y_clust, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1e22250d6fde4cad012ac66805ba112157fe593"
   },
   "source": [
    "*More on clustering metrics can be found in [DataCamp Tutorial](https://www.datacamp.com/community/tutorials/machine-learning-python).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4859477e2f03dff8379fd94ced4c538024a3a9da",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means(n_clust=2, data_frame=Data, true_labels=Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf131bc7df0790288abdf2fdff3c24e0518825bf"
   },
   "source": [
    "**It looks like algorithm found patterns for Moving and Not-Moving activity with high level of accuracy.**\n",
    "\n",
    "**Check how it will cluster by 6 clusters (original number of classes).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77fc311b114a73666db3d1884fd8855494b9cf98",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means(n_clust=6, data_frame=Data, true_labels=Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9ddf90d06a4eda0f9e97555cd39364d976c9d94"
   },
   "source": [
    "**Doesn't look like good connection between clusters and original labels so I will stick with 2 clusters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14fb8f60665b00277373839b7deca6a2bb783ae9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change labels into binary: 0 - not moving, 1 - moving\n",
    "Labels_binary = Labels.copy()\n",
    "for i in range(len(Labels_binary)):\n",
    "    if (Labels_binary[i] == 'STANDING' or Labels_binary[i] == 'SITTING' or Labels_binary[i] == 'LAYING'):\n",
    "        Labels_binary[i] = 0\n",
    "    else:\n",
    "        Labels_binary[i] = 1\n",
    "Labels_binary = np.array(Labels_binary.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c5902af7a341c558ee3d04bddc8a82db89ba2d4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_means(n_clust=2, data_frame=Data, true_labels=Labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9fab904423a94794b73a9fe02e9279d281eeef1b"
   },
   "source": [
    "### Principal component analysis (PCA)\n",
    "\n",
    "> Principal Component Analysis is a dimension-reduction tool that can be used to reduce a large set of variables to a small set that still contains most of the information in the large set.\n",
    "\n",
    "**2-cluster algorithm seems to fbe able to find patterns for moving/not-moving labels perfectly so far, but let's see if it can still be improved by dimension reduction. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "163528d7a251f7a95e5885aa6dd6e909755bcdd1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check for optimal number of features\n",
    "pca = PCA(random_state=123)\n",
    "pca.fit(Data)\n",
    "features = range(pca.n_components_)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(features[:15], pca.explained_variance_[:15], color='lightskyblue')\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('Variance')\n",
    "plt.xticks(features[:15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95185b3da6fe8962a6fb7e46517cc68024ec1593"
   },
   "source": [
    "**1 feature seems to be best fit for our algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd1680834e4fd355bcfa9a60e389e72f05e56a26",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_transform(n_comp):\n",
    "    pca = PCA(n_components=n_comp, random_state=123)\n",
    "    global Data_reduced\n",
    "    Data_reduced = pca.fit_transform(Data)\n",
    "    print('Shape of the new Data df: ' + str(Data_reduced.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43f3100460829ed0f65a616b5dde28f2f6afd129",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pca_transform(n_comp=3)\n",
    "# k_means(n_clust=2, data_frame=Data_reduced, true_labels=Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "32a1efa2e6a608615b84aa162e15d41de237c39e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# colors = ['green', 'blue', 'orange', 'gray', 'pink', 'red']\n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# for i in range(len(colors)):\n",
    "#     x = Data_reduced[:, 0][Labels == Labels_keys[i]]\n",
    "#     y = Data_reduced[:, 1][Labels == Labels_keys[i]]\n",
    "#     z = Data_reduced[:, 2][Labels == Labels_keys[i]]\n",
    "#     ax.scatter(xs=x, ys=y, zs=z, zdir='y', s=20, c=colors[i], alpha=0.2)\n",
    "\n",
    "# ax.set_xlabel('First Principal Component')\n",
    "# ax.set_ylabel('Second Principal Component')\n",
    "# ax.set_zlabel('Third Principal Component')\n",
    "# ax.set_title(\"PCA Scatter Plot\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1930c533868db12321e36543692211c739595933",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_transform(n_comp=1)\n",
    "k_means(n_clust=2, data_frame=Data_reduced, true_labels=Labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d10035131986233b1be712972047543386f40b05"
   },
   "source": [
    "**Inertia and Silhouette seems to be much better now after reduction. **\n",
    "\n",
    "**Just check clustering model for 2 components.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "117254747dc177e5f18a3077eab9f2b509e5a0af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_transform(n_comp=2)\n",
    "k_means(n_clust=2, data_frame=Data_reduced, true_labels=Labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab1886cbcd7f99f2b50d99171d6d9e752355f393"
   },
   "source": [
    "**No improvements here.**\n",
    "\n",
    "**So far it seems like this was best I could do. Still learning clustering algorithms and I might come back to this project later.**\n",
    "\n",
    "**If you know any interesting dataset to practice clustering on (not Iris dataset, haha), please suggest!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
